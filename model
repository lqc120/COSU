# -*-coding:utf-8-*-
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision


class LayerNorm(nn.Module):
    r""" modified into 3D.

    LayerNorm that supports two data formats: channels_last (default) or channels_first.
    The ordering of the dimensions in the inputs. channels_last corresponds to inputs with
    shape (batch_size, height, width, channels) while channels_first corresponds to inputs
    with shape (batch_size, channels, depth, height, width).
    """
    def __init__(self, normalized_shape, eps=1e-6, data_format="channels_last"):
        super().__init__()
        self.weight = nn.Parameter(torch.ones(normalized_shape))
        self.bias = nn.Parameter(torch.zeros(normalized_shape))
        self.eps = eps
        self.data_format = data_format
        if self.data_format not in ["channels_last", "channels_first"]:
            raise NotImplementedError
        self.normalized_shape = (normalized_shape,)

    def forward(self, x):
        if self.data_format == "channels_last":
            return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)
        elif self.data_format == "channels_first":
            u = x.mean(1, keepdim=True)
            s = (x - u).pow(2).mean(1, keepdim=True)
            x = (x - u) / torch.sqrt(s + self.eps)
            x = self.weight[:, None, None, None] * x + self.bias[:, None, None, None]
            return x


class ECR_block(nn.Module):
    def __init__(self, channels, rate=1):
        super(ECR_block, self).__init__()
        self.conv = nn.Sequential(
            nn.Conv3d(channels, channels*rate, kernel_size=(1, 1, 1), stride=(1, 1, 1), padding=0),
            LayerNorm(channels*rate, eps=1e-6, data_format="channels_first"),
            nn.Conv3d(channels*rate, channels*rate, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1),
                      groups=channels*rate),
            nn.GELU(),
            nn.Conv3d(channels*rate, channels, kernel_size=(1, 1, 1), stride=(1, 1, 1), padding=0)
        )

    def forward(self, x):
        y = self.conv(x)+x
        return y


class CONet(nn.Module):
    def __init__(self,  channels):
        super(CONet, self).__init__()
        dims = [channels, channels * 4, channels * 16, channels * 64]
        self.cs1 = CS1()
        self.cs2 = CS2()
        self.cs3 = CS3()
        self.scmodule = SC(dims[0])
        self.acs1 = ACS1()
        self.acs2 = ACS2()
        self.acs3 = ACS3()
        self.en0 = ECR_block(dims[0], rate=1)
        self.en1 = ECR_block(dims[1], rate=2)
        self.en2 = ECR_block(dims[2], rate=3)
        self.en3 = ECR_block(dims[3], rate=4)
        self.de3 = ECR_block(dims[3], rate=4)
        self.de2 = ECR_block(dims[2], rate=3)
        self.de1 = ECR_block(dims[1], rate=2)
        self.de0 = ECR_block(dims[0], rate=1)
        self.down0 = downs(rate=4)
        self.down1 = downs(rate=8)
        self.down2 = downs(rate=16)
        self.down3 = downs(rate=32)

        
    def forward(self, x, y_0, y_1, y_2, y_3):
        size = x.size()
        print('x0', x.shape)
        y_0 = self.scmodule(y_0)
        y_0 = F.interpolate(y_0, size=(2, size[3], size[3]), mode='trilinear', align_corners=True)
        x = x * y_0 + x
        x = self.en0(x)
        x0 = x
        x = self.cs1(x)
        y_1 = self.scmodule(y_1)
        y_1 = F.interpolate(y_1, size=(2, size[3], size[3]), mode='trilinear', align_corners=True)
        x = x * self.cs1(y_1) + x
        x = self.en1(x)
        x1 = x
        x = self.cs2(x)
        y_2 = self.scmodule(y_2)
        y_2 = F.interpolate(y_2, size=(2, size[3], size[3]), mode='trilinear', align_corners=True)
        x = x * self.cs2(self.cs1(y_2)) + x
        x = self.en2(x)
        x2 = x
        x = self.cs3(x)
        y_3 = self.scmodule(y_3)
        y_3 = F.interpolate(y_3, size=(2, size[3], size[3]), mode='trilinear', align_corners=True)
        x = x * self.cs3(self.cs2(self.cs1(y_3))) + x
        x = self.en3(x)
        out_3 = self.down3(self.acs1(self.acs2(self.acs3(x))))
        x = self.de2(self.acs3(self.de3(x))+x2)
        out_2 = self.down2(self.acs1(self.acs2(x)))
        x = self.de1(self.acs2(x)+x1)
        out_1 = self.down1(self.acs1(x))
        x = self.de0(self.acs1(x)+x0)
        out_0 = self.down0(x)
        return x, out_0, out_1, out_2, out_3


class CS1(nn.Module):
    def __init__(self):
        super(CS1, self).__init__()

    def forward(self, x):
        size = int(x.size()[3]) // 2
        ZS = x[:, :, :, :size, :size]
        YS = x[:, :, :, :size, size:]
        ZX = x[:, :, :, size:, :size]
        YX = x[:, :, :, size:, size:]
        YS = torch.transpose(torchvision.transforms.RandomHorizontalFlip(p=1)(YS), 4, 3)
        ZX = torch.transpose(torchvision.transforms.RandomVerticalFlip(p=1)(ZX), 4, 3)
        YX = torchvision.transforms.RandomVerticalFlip(p=1)(YX)
        YX = torch.transpose(torchvision.transforms.RandomHorizontalFlip(p=1)(YX), 4, 3)
        y = torch.cat((ZS, YS, YX, ZX), 1)
        return y


class CS2(nn.Module):
    def __init__(self):
        super(CS2, self).__init__()

    def forward(self, x):
        size = int(x.size()[3]) // 2
        ZS = x[:, :, :, :size, :size]
        YS = x[:, :, :, :size, size:]
        ZX = x[:, :, :, size:, :size]
        YX = x[:, :, :, size:, size:]
        y = torch.cat((ZS, YS, ZX, YX), 1)
        return y


class CS3(nn.Module):
    def __init__(self):
        super(CS3, self).__init__()
        self.slice = CS2()

    def forward(self, x):
        scale = int(x.size()[1]) // 4
        ZS = x[:, 0:scale, :, :, :]
        YS = x[:, scale:scale * 2, :, :, :]
        ZX = x[:, scale * 2:scale * 3, :, :, :]
        YX = x[:, scale * 3:scale * 4, :, :, :]
        ZS = self.slice(ZS)
        YS = self.slice(YS)
        ZX = self.slice(ZX)
        YX = self.slice(YX)
        y = torch.cat((ZS, YS, ZX, YX), 1)
        return y


class ACS1(nn.Module):
    def __init__(self):
        super(ACS1, self).__init__()
        
    def forward(self, x):
        size0 = int(x.size()[0])
        size1 = int(x.size()[1]) // 4
        size2 = int(x.size()[2])
        size3 = int(x.size()[3])
        size4 = size3 * 2
        scale1 = size1
        scale2 = size1 * 2
        scale3 = size1 * 3
        scale4 = size1 * 4
        y = torch.Tensor(size0, size1, size2, size4, size4).cuda()
        ZS = x[:, 0:scale1, :, :, :]
        YS = x[:, scale1:scale2, :,:, :]
        YX = x[:, scale2:scale3, :,:, :]
        ZX = x[:, scale3:scale4, :, :, :]
        YS = torch.transpose(YS, 4, 3)
        YS = torchvision.transforms.RandomHorizontalFlip(p=1)(YS)
        ZX = torch.transpose(ZX, 4, 3)
        ZX = torchvision.transforms.RandomVerticalFlip(p=1)(ZX)
        YX = torch.transpose(YX, 4, 3)
        YX = torchvision.transforms.RandomVerticalFlip(p=1)(YX)
        YX = torchvision.transforms.RandomHorizontalFlip(p=1)(YX)
        y[:, :, :, :size3, :size3] = ZS[:, :, :, :, :]
        y[:, :, :, :size3, size3:] = YS[:, :, :, :, :]
        y[:, :, :, size3:, :size3] = ZX[:, :, :, :, :]
        y[:, :, :, size3:, size3:] = YX[:, :, :, :, :]
        return y


class ACS2(nn.Module):
    def __init__(self):
        super(ACS2, self).__init__()
        
    def forward(self, x):
        size0 = int(x.size()[0])
        size1 = int(x.size()[1]) // 4
        size2 = int(x.size()[2])
        size3 = int(x.size()[3])
        size4 = size3 * 2
        scale1 = size1
        scale2 = size1 * 2
        scale3 = size1 * 3
        scale4 = size1 * 4
        y = torch.Tensor(size0, size1, size2, size4, size4).cuda()
        ZS = x[:, 0:scale1, :, :, :]
        YS = x[:, scale1:scale2, :, :, :]
        ZX = x[:, scale2:scale3, :, :, :]
        YX = x[:, scale3:scale4, :, :, :]
        y[:, :, :, :size3, :size3] = ZS[:, :, :, :, :]
        y[:, :, :, :size3, size3:] = YS[:, :, :, :, :]
        y[:, :, :, size3:, :size3] = ZX[:, :, :, :, :]
        y[:, :, :, size3:, size3:] = YX[:, :, :, :, :]
        return y


class ACS3(nn.Module):
    def __init__(self):
        super(ACS3, self).__init__()
        self.anti_slice = ACS2()

    def forward(self, x):
        scale = int(x.size()[1]) // 4
        ZS = x[:, 0:scale, :, :, :]
        YS = x[:, scale:scale * 2, :, :, :]
        ZX = x[:, scale * 2:scale * 3, :, :, :]
        YX = x[:, scale * 3:scale * 4, :, :, :]
        ZS = self.anti_slice(ZS)
        YS = self.anti_slice(YS)
        ZX = self.anti_slice(ZX)
        YX = self.anti_slice(YX)
        x = torch.cat((ZS, YS, ZX, YX), 1)
        return x


class MC(nn.Module):
    def __init__(self, channels):
        super(MC, self).__init__()
        self.conv_gelu_conv = nn.Sequential(
            nn.Conv3d(channels, channels * 4, kernel_size=(1, 1, 1),stride=(1, 1, 1), padding=(0, 0, 0)),
            nn.GELU(),
            nn.Conv3d(channels * 4, channels, kernel_size=(1, 1, 1), stride=(1, 1, 1), padding=(0, 0, 0))
        )

    def _res(self, x):  # B, C, V, W, H
        x_copy = torch.zeros_like(x).cuda()
        x_copy[:, :, 0, :, :] = x[:, :, 1, :, :]
        x_copy[:, :, 1, :, :] = x[:, :, 0, :, :]
        res = x_copy - x
        res = torch.abs(res)
        return res

    def forward(self, x1, x2):
        y = self.conv_gelu_conv(self._res(torch.sigmoid(x1))) + x2
        return y


class SC(nn.Module):
    def __init__(self, channels):
        super(SC, self).__init__()
        self.ln_gelu_conv = nn.Sequential(
            LayerNorm(channels, eps=1e-6, data_format="channels_first"),
            nn.GELU(),
            nn.Conv3d(channels, channels, kernel_size=(3, 7, 7), stride=(1, 1, 1), padding=(1, 3, 3))
        )

    def forward(self,  x):
        y = torch.sigmoid(self.ln_gelu_conv(x))
        return y

class downs(nn.Module):
    def __init__(self, rate=2):
        super(downs, self).__init__()
        self.maxpool = nn.MaxPool2d(kernel_size=(rate, rate), stride=(rate, rate), padding=(0, 0))
        self.rate = rate

    def forward(self, x2):
        B, C4, T4, H4, W4 = x2.size()
        x2_flatten = x2.view(B, C4 * T4, H4, W4)
        x2_flatten_up = self.maxpool(x2_flatten)
        x2_up = x2_flatten_up.view(B, C4, T4, H4 // self.rate, W4 // self.rate)
        return x2_up

